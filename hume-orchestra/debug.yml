---
# Source: hume-orchestra/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-hume-orchestra
  labels:
    helm.sh/chart: hume-orchestra-2.18.0-alpha1
    app.kubernetes.io/name: hume-orchestra
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.18.0-SNAPSHOT"
    app.kubernetes.io/managed-by: Helm
---
# Source: hume-orchestra/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.5
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  postgres-password: "N3lDQW9Pekp2dA=="
  password: "b3JjaGVzdHJh"
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: hume-orchestra/charts/zookeeper/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-zookeeper-scripts
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-11.1.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
data:
  init-certs.sh: |-
    #!/bin/bash
  setup.sh: |-
    #!/bin/bash

    # Execute entrypoint as usual after obtaining ZOO_SERVER_ID
    # check ZOO_SERVER_ID in persistent volume via myid
    # if not present, set based on POD hostname
    if [[ -f "/bitnami/zookeeper/data/myid" ]]; then
        export ZOO_SERVER_ID="$(cat /bitnami/zookeeper/data/myid)"
    else
        HOSTNAME="$(hostname -s)"
        if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
            ORD=${BASH_REMATCH[2]}
            export ZOO_SERVER_ID="$((ORD + 1 ))"
        else
            echo "Failed to get index from hostname $HOST"
            exit 1
        fi
    fi
    exec /entrypoint.sh /run.sh
---
# Source: hume-orchestra/templates/orchestra-controller-configmap.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-hume-orchestra-orchestra-controller-configmap
  labels:
    app.kubernetes.io/name: release-name-hume-orchestra-web
    app.kubernetes.io/version: "2.18.0-SNAPSHOT"
    helm.sh/chart: release-name-hume-orchestra
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: release-name-hume-orchestra
data:
  spring.datasource.url: jdbc:postgresql://release-name-postgresql:5432/orchestra
  spring.datasource.username: orchestra
  spring.datasource.password: orchestra
  orchestra.storage.engine: "db"
  orchestra.cluster.enabled: "true"
  orchestra.instance.mode: "clusterController"
  orchestra.cluster.nodes.active.number: "2"
  orchestra.cluster.node.advertised.protocol: "http"
#   orchestra.cluster.node.advertised.host=orchestra-cluster-member-1
  orchestra.cluster.zookeeper.host: "-zookeeper"
  orchestra.cluster.zookeeper.port: "2181"
---
# Source: hume-orchestra/templates/orchestra-worker-configmap.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-hume-orchestra-orchestra-worker-configmap
  labels:
    app.kubernetes.io/name: release-name-hume-orchestra-web
    app.kubernetes.io/version: "2.18.0-SNAPSHOT"
    helm.sh/chart: release-name-hume-orchestra
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: release-name-hume-orchestra
data:
  spring.datasource.url: jdbc:postgresql://release-name-postgresql:5432/orchestra
  spring.datasource.username: orchestra
  spring.datasource.password: orchestra
  orchestra.storage.engine: "db"
  orchestra.cluster.enabled: "true"
  orchestra.instance.mode: "clusterMember"
  orchestra.cluster.node.advertised.protocol: "http"
  orchestra.cluster.node.advertised.host: release-name-hume-orchestra-worker
  orchestra.cluster.zookeeper.host: release-name-zookeeper
  orchestra.cluster.zookeeper.port: "2181"
---
# Source: hume-orchestra/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.5
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: hume-orchestra/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.5
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: hume-orchestra/charts/zookeeper/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-zookeeper-headless
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-11.1.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-client
      port: 2181
      targetPort: client
    - name: tcp-follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: zookeeper
---
# Source: hume-orchestra/charts/zookeeper/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-zookeeper
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-11.1.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-client
      port: 2181
      targetPort: client
      nodePort: null
    - name: tcp-follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: zookeeper
---
# Source: hume-orchestra/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-hume-orchestra-controller
  labels:
    helm.sh/chart: hume-orchestra-2.18.0-alpha1
    app.kubernetes.io/name: hume-orchestra
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.18.0-SNAPSHOT"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8100
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: hume-orchestra
    app.kubernetes.io/instance: release-name
---
# Source: hume-orchestra/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-hume-orchestra-worker
  labels:
    helm.sh/chart: hume-orchestra-2.18.0-alpha1
    app.kubernetes.io/name: hume-orchestra
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.18.0-SNAPSHOT"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8101
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: hume-orchestra
    app.kubernetes.io/instance: release-name
---
# Source: hume-orchestra/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-hume-orchestra-orchestra-controller
  labels:
    app.kubernetes.io/name: release-name-hume-orchestra-web
    app.kubernetes.io/version: "2.18.0-SNAPSHOT"
    helm.sh/chart: release-name-hume-orchestra
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: release-name-hume-orchestra
spec:
  replicas: 1
  
  selector:
    matchLabels:
      app: release-name-hume-orchestra-orchestra-controller
  template:
    metadata:
      labels:
        app: release-name-hume-orchestra-orchestra-controller
    spec:
      imagePullSecrets:
        - name: image-pull-secret
      serviceAccountName: release-name-hume-orchestra
      
      securityContext:
        {}
      # temporary disable serviceLinks until single uri config setting is available in orchestra-controller for eventstore connection
      enableServiceLinks: false
      volumes:
      containers:
        - name: release-name-hume-orchestra-orchestra-controller
          securityContext:
            {}
          image: "docker.graphaware.com/internal/hume-orchestra:2.18.0-SNAPSHOT"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health
              port: http
            initialDelaySeconds: 
            periodSeconds: 5
            failureThreshold: 10
          startupProbe:
            httpGet:
              path: /actuator/health
              port: http
            initialDelaySeconds: 
            periodSeconds: 7
            failureThreshold: 20
          envFrom:
            - configMapRef:
                name: release-name-hume-orchestra-orchestra-controller-configmap
          env:
          resources:
            null
---
# Source: hume-orchestra/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.1.5
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
spec:
  replicas: 1
  serviceName: release-name-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-12.1.5
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: primary
      annotations:
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      initContainers:
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:15.1.0-debian-11-r12
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "orchestra"
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgres-password
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: POSTGRES_DB
              value: "orchestra"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "orchestra" -d "dbname=orchestra" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                
                - |
                  exec pg_isready -U "orchestra" -d "dbname=orchestra" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: hume-orchestra/charts/zookeeper/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-zookeeper
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-11.1.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
    role: zookeeper
spec:
  replicas: 1
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app.kubernetes.io/name: zookeeper
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: zookeeper
  serviceName: release-name-zookeeper-headless
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  template:
    metadata:
      annotations:
      labels:
        app.kubernetes.io/name: zookeeper
        helm.sh/chart: zookeeper-11.1.3
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: zookeeper
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zookeeper
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: zookeeper
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      initContainers:
      containers:
        - name: zookeeper
          image: docker.io/bitnami/zookeeper:3.8.1-debian-11-r6
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1001
          command:
            - /scripts/setup.sh
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: ZOO_DATA_LOG_DIR
              value: ""
            - name: ZOO_PORT_NUMBER
              value: "2181"
            - name: ZOO_TICK_TIME
              value: "2000"
            - name: ZOO_INIT_LIMIT
              value: "10"
            - name: ZOO_SYNC_LIMIT
              value: "5"
            - name: ZOO_PRE_ALLOC_SIZE
              value: "65536"
            - name: ZOO_SNAPCOUNT
              value: "100000"
            - name: ZOO_MAX_CLIENT_CNXNS
              value: "60"
            - name: ZOO_4LW_COMMANDS_WHITELIST
              value: "srvr, mntr, ruok"
            - name: ZOO_LISTEN_ALLIPS_ENABLED
              value: "no"
            - name: ZOO_AUTOPURGE_INTERVAL
              value: "0"
            - name: ZOO_AUTOPURGE_RETAIN_COUNT
              value: "3"
            - name: ZOO_MAX_SESSION_TIMEOUT
              value: "40000"
            - name: ZOO_SERVERS
              value: release-name-zookeeper-0.release-name-zookeeper-headless.default.svc.cluster.local:2888:3888::1 
            - name: ZOO_ENABLE_AUTH
              value: "no"
            - name: ZOO_ENABLE_QUORUM_AUTH
              value: "no"
            - name: ZOO_HEAP_SIZE
              value: "1024"
            - name: ZOO_LOG_LEVEL
              value: "ERROR"
            - name: ALLOW_ANONYMOUS_LOGIN
              value: "yes"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
          ports:
            - name: client
              containerPort: 2181
            - name: follower
              containerPort: 2888
            - name: election
              containerPort: 3888
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
          volumeMounts:
            - name: scripts
              mountPath: /scripts/setup.sh
              subPath: setup.sh
            - name: data
              mountPath: /bitnami/zookeeper
      volumes:
        - name: scripts
          configMap:
            name: release-name-zookeeper-scripts
            defaultMode: 0755
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: hume-orchestra/templates/statefulset.yml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-hume-orchestra-sts
  labels:
    helm.sh/chart: hume-orchestra-2.18.0-alpha1
    app.kubernetes.io/name: hume-orchestra
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.18.0-SNAPSHOT"
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: "orchestra-worker"
  replicas: 2
  selector:
    matchLabels:
      app: release-name-hume-orchestra-orchestra
  template:
    metadata:
      labels:
        app: release-name-hume-orchestra-orchestra
    spec:
      imagePullSecrets:
        - name: image-pull-secret
      serviceAccountName: release-name-hume-orchestra
      
      securityContext:
        {}
      containers:
        - name: release-name-hume-orchestra-orchestra
          securityContext:
            {}
          image: "docker.graphaware.com/internal/hume-orchestra:2.18.0-SNAPSHOT"
          imagePullPolicy: Always
          ports:
            - name: orchestra
              containerPort: 8100
              protocol: TCP
            - name: metrics
              containerPort: 7001
              protocol: TCP
          startupProbe:
            httpGet:
              path: /actuator/metrics
              port: metrics
            failureThreshold: 20
            periodSeconds: 7
          livenessProbe:
            httpGet:
              path: /actuator/metrics
              port: metrics
            failureThreshold: 10
            periodSeconds: 5
            timeoutSeconds: 10
          readinessProbe:
            httpGet:
              path: /actuator/metrics
              port: metrics
            failureThreshold: 10
            periodSeconds: 5
            timeoutSeconds: 10
          envFrom:
            - configMapRef:
                name: release-name-hume-orchestra-orchestra-worker-configmap
          env:
          resources:
            null
          volumeMounts:
      volumes:
  volumeClaimTemplates:
---
# Source: hume-orchestra/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "release-name-hume-orchestra-test-connection"
  labels:
    helm.sh/chart: hume-orchestra-2.18.0-alpha1
    app.kubernetes.io/name: hume-orchestra
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.18.0-SNAPSHOT"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['release-name-hume-orchestra:']
  restartPolicy: Never
